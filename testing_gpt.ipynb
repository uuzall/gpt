{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload \n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim \n",
    "import torch.nn.functional as F \n",
    "from torch.utils.data import DataLoader \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import data\n",
    "import gpt \n",
    "from tqdm import tqdm, trange\n",
    "import json \n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu' \n",
    "if device == 'cuda': \n",
    "  print(torch.cuda.get_device_name()) \n",
    "else: \n",
    "  print(device) \n",
    "\n",
    "with open('config.json', 'r') as file: \n",
    "  config = json.load(file)\n",
    "\n",
    "lr = config['lr']\n",
    "bs = config['batch_size']\n",
    "\n",
    "vocab_size, encode = data._init_data() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.873817 M parameters.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = gpt.gpt_model(vocab_size=vocab_size).to(device) \n",
    "print(sum(p.numel() for p in model.parameters())/1e6, 'M parameters.')\n",
    "\n",
    "model.load_state_dict(torch.load('models/best_performing.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sen = 'Ross Geller: What did you do?\\nChandler Bing: '\n",
    "sen = \"TRANSCRIPT_NOTE: \\nJoey Tribbiani: All right, all right, all right, let's play one more time, ok? And remember, if I win you do not move to Paris.\\nRachel Green: Ok! Can't believe I'm risking this again, but you're on! All right Joe, you remember the rules! Heads I win, tails you lose.\\nJoey Tribbiani: Just flip!\\nRachel Green: Ha, tails!\\nJoey Tribbiani: Damnit!\\nChandler Bing: Hey!\\nJoey Tribbiani: Hey!\\nChandler Bing: So we thought we'd throw you little going away party around seven.\\nRachel Green:\"\n",
    "sen = torch.tensor(encode(sen), device=device).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRANSCRIPT_NOTE: \n",
      "Joey Tribbiani: All right, all right, all right, let's play one more time, ok? And remember, if I win you do not move to Paris.\n",
      "Rachel Green: Ok! Can't believe I'm risking this again, but you're on! All right Joe, you remember the rules! Heads I win, tails you lose.\n",
      "Joey Tribbiani: Just flip!\n",
      "Rachel Green: Ha, tails!\n",
      "Joey Tribbiani: Damnit!\n",
      "Chandler Bing: Hey!\n",
      "Joey Tribbiani: Hey!\n",
      "Chandler Bing: So we thought we'd throw you little going away party around seven.\n",
      "Rachel Green: Aw ell that's good.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(data.decode(model.generate(sen, 512, limit_sentence=True)[0].tolist())) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI_310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
